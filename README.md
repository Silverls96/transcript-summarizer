# Batch Audio Processing with Whisper and LiteLLM

This project is designed to process audio files using Whisper for speech-to-text transcription and LiteLLM for generating responses to the transcribed text. It supports both batch processing of audio files and direct text input for response generation.

## Table of Contents

- [Introduction](#introduction)
- [Requirements](#requirements)
- [Usage](#usage)
- [Features](#features)
- [Troubleshooting](#troubleshooting)

## Introduction

This tool automates the process of transcribing audio files and generating intelligent responses using LiteLLM. It is built with Whisper for transcription and utilizes LiteLLM's API for response generation.

## Requirements

- **Python 3.8+**: Ensure you have Python installed on your system.
- **Whisper Model**: Uses the Whisper "turbo" model for transcription.
- **LiteLLM API Key**: Requires an API key for LiteLLM.
- **OpenRouter API Key**: Needed if using OpenRouter for LiteLLM access.
- **Rich Console**: For enhanced console output.
- **Litellm Library**: For interacting with LiteLLM.
- **ffmpeg**: For load audio.

### Installation

##### To install the required packages, run:

```bash
pip install -r requirements.txt
```

##### To install choco, here is the guide
First, ensure that you are using an administrative shell - you can also install as a non-admin, check out Non-Administrative Installation.
Install with powershell.exe

With PowerShell, you must ensure Get-ExecutionPolicy is not Restricted. We suggest using Bypass to bypass the policy to get things installed or AllSigned for quite a bit more security.

Run Get-ExecutionPolicy. If it returns Restricted, then run Set-ExecutionPolicy AllSigned or Set-ExecutionPolicy Bypass -Scope Process.

Now run the following command:
```
Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https://community.chocolatey.org/install.ps1'))
```
Paste the copied text into your shell and press Enter.
Wait a few seconds for the command to complete.
If you don't see any errors, you are ready to use Chocolatey! Type choco or choco -? now, or see Getting Started for usage instructions.

##### To install ffmpeg, run:
```bash
choco install ffmpeg (https://chocolatey.org/install)
```

## Usage

### Command-Line Arguments

The project uses `argparse` for command-line arguments. You can choose to process audio files in a default "inputs" folder or provide paths to specific text files.

#### Process Audio Files

```bash
python app.py -a
```

#### Process Text Files

```bash
python app.py -t file1.txt file2.txt
```

### Environment Variables

Set the following environment variables in a `.env` file:

- `API_KEY`: Your OpenRouter API key.
- `LLM_MODEL`: The LiteLLM model to use. (e.g openrouter/deepseek/deepseek-r1-zero:free, azure_ai/DeepSeek-R1)
- `FOLDER`: The folder where your .wav or audio files located (Optional)
- `API_VERSION`: The API version of the models (Optional)
- `LLM_URL`: The url base api of the models (Optional)

### Run Bat File
```bash
run.bat
```

## Features

- **Batch Audio Processing**: Transcribes multiple audio files and generates responses.
- **Text Input Support**: Allows processing text files directly for response generation.
- **Timing Information**: Includes transcription and response generation times in output files.
- **Output Organization**: Saves transcriptions and responses in separate folders.

## Troubleshooting

- **Missing Dependencies**: Ensure all required packages are installed.
- **API Key Issues**: Verify that your API keys are correct and properly set in the `.env` file.
- **File Not Found Errors**: Check that all file paths are correct and accessible.

## Post-Processing with NotebookLM

After running `run.bat`, the responses will be saved in a designated folder. To upload these results to [NotebookLM](https://notebooklm.google/) and ask questions:

1. **Upload Results to NotebookLM**:
   - Log in to your NotebookLM account.
   - Navigate to the upload section.
   - Select the folder containing the response files generated by this tool.

2. **Ask Questions in NotebookLM**:
   - Once the files are uploaded, you can ask questions related to the content of the transcriptions and responses.
   - Use the NotebookLM interface to input your questions and receive answers based on the uploaded data.

---